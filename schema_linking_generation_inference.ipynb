{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZK83JZaKSxu2",
    "outputId": "174c225b-5dbc-4412-8786-6d1832092ca4"
   },
   "outputs": [],
   "source": [
    "#!pip install -U accelerate bitsandbytes peft transformers datasets trl git-lfs wandb flash-attn sql-metadata scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "690Zw7_2SkCU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/jzhao815/.conda/envs/dtssql/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-26 08:27:45,389 - modelscope - INFO - PyTorch version 2.2.2 Found.\n",
      "2024-04-26 08:27:45,391 - modelscope - INFO - Loading ast index from /hpc2hdd/home/jzhao815/.cache/modelscope/ast_indexer\n",
      "2024-04-26 08:27:46,341 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 2bbcf3979e8ce95c88f5a68d5ba83352 and a total number of 972 components indexed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from torch import cuda\n",
    "from sql_metadata import Parser\n",
    "from tqdm import tqdm\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f0d5986597124099bf09d298575c5126",
      "6e2db7ee351248f4b08587a275bfde8a",
      "30c71ab2e03d40d7968624b3dc15656c",
      "16576d8e9bca4a978cf1807800d2993f",
      "4fde92ad16cc4bd18d9c48dc91d28696",
      "08d81d35451441abb5a8069816d96bf4",
      "eed7debb70434c16aeda3d744d131d30",
      "a49f174c025644d7a99e414244390a0d",
      "f30459f7d7254a7abc3cabe448a60681",
      "f87cf27bd7aa4c5fbcb796155236a983",
      "a0010a2bcdc94d609fe271442e1db441"
     ]
    },
    "id": "11wfu6AdTK1C",
    "outputId": "56652c73-e2f9-492b-ba43-826ba5cde889"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.11.8 ('autogptq': conda)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: 'conda install -n autogptq ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#use local model or from huggingface/modelscope\n",
    "model_name = \"qwen/CodeQwen1.5-7B-Chat\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    attn_implementation=\"flash_attention_2\", # use with amper architecture\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    #quantization_config=bnb_config, # use when low on memory\n",
    "    device_map = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "kUqzZ2bFVdd9",
    "outputId": "5a572914-766e-4b93-cb67-a31efc786bb8"
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, \"./final_checkpoint_part1\",torch_dtype = torch.bfloat16)\n",
    "model = model.merge_and_unload()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5106]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(' ;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria\n",
    "class EosListStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, eos_sequence = [6203]):\n",
    "        self.eos_sequence = eos_sequence\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        last_ids = input_ids[:,-len(self.eos_sequence):].tolist()\n",
    "        return self.eos_sequence in last_ids\n",
    "    \n",
    "def append_string_to_file(text, file_path):\n",
    "  with open(file_path, 'a') as file:\n",
    "      file.write(text + '\\n')\n",
    "\n",
    "def remove_spaces(text):\n",
    "  return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def call_mistral(inputs):\n",
    "  output_tokens = model.generate(inputs, max_new_tokens=250, do_sample=False, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id, stopping_criteria = [EosListStoppingCriteria()])\n",
    "  return tokenizer.decode(output_tokens[0][len(inputs[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgz-2h6SVj1Z",
    "outputId": "ff9a916b-c865-4e74-b4ca-9dcb8de57730"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./validation/spider_syn_dataset.csv\")\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "  question = row['question']\n",
    "  query = row['query']\n",
    "  database_schema = row['database_schema']\n",
    "  db_id = row['db_id']\n",
    "  user_message = f\"\"\"Given the following SQL tables, your job is to determine the columns and tables that the question is referring to.\n",
    "{database_schema}\n",
    "###\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "  messages = [\n",
    "      {\"role\": \"user\", \"content\": user_message.strip()}\n",
    "  ]\n",
    "  inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\",add_generation_prompt=True,tokenize = True).to(model.device)\n",
    "  response = call_mistral(inputs)\n",
    "  if \";\" in response:\n",
    "    response = response.split(\";\")[0]\n",
    "    if \"Tables:\" in response:\n",
    "      response = response.split(\"Tables:\")[1]\n",
    "  response = re.sub(r'\\s+', ' ', response).strip()\n",
    "  try:\n",
    "    ref_rables = \", \".join(Parser(query).tables)\n",
    "  except Exception:\n",
    "    continue\n",
    "  print(\"\\n\")\n",
    "  print(response)\n",
    "  print(ref_rables)\n",
    "  print(\"============================\")\n",
    "  results.append([response, ref_rables, query,row['question'],row['db_id']])\n",
    "  new_df = pd.DataFrame(results, columns = ['predicted_tables','reference_tables','query','question','db_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(new_df)\n",
    "total_accuracy = 0\n",
    "filtered_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "\n",
    "for index, row in new_df.iterrows():\n",
    "    \n",
    "    if not row['predicted_tables'] or pd.isna(row['predicted_tables']):\n",
    "        continue\n",
    "    predicted_tables = row['predicted_tables'].split(\", \")\n",
    "    reference_tables = row['reference_tables'].split(\", \")\n",
    "    \n",
    "    # Convert to lowercase and strip whitespace for comparison\n",
    "    predicted_tables = [x.lower().replace(\"--\",\"\").replace(\"**\",\"\").strip() for x in predicted_tables]\n",
    "    reference_tables = [x.lower().strip() for x in reference_tables]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    if set(predicted_tables) == set(reference_tables):\n",
    "        total_accuracy += 1\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    true_positives = len(set(predicted_tables) & set(reference_tables))\n",
    "    false_positives = len(set(predicted_tables) - set(reference_tables))\n",
    "    false_negatives = len(set(reference_tables) - set(predicted_tables))\n",
    "\n",
    "    if true_positives == len(reference_tables):\n",
    "        filtered_accuracy += 1\n",
    "    \n",
    "    if len(predicted_tables) > 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "\n",
    "# Calculate average precision and recall\n",
    "avg_precision = total_precision / total_samples\n",
    "avg_recall = total_recall / total_samples\n",
    "\n",
    "# Calculate total accuracy\n",
    "accuracy = total_accuracy / total_samples\n",
    "filtered_accuracy = filtered_accuracy / total_samples\n",
    "\n",
    "print(\"Total Accuracy:\", accuracy)\n",
    "print(\"Filtered Accuracy:\", filtered_accuracy)\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "\n",
    "new_df.to_csv(\"generated_test_schema_links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2147 [00:00<?, ?it/s]\n",
      "No chat template is defined for this tokenizer - using the default template for the GPT2TokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n",
      " 22%|██▏       | 481/2147 [00:04<00:21, 77.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No close match found for table students.student_id in database.\n",
      "Warning: No close match found for table students.student_id in database.\n",
      "Warning: No close match found for table ref_address_types.address_type_description in database.\n",
      "Warning: No close match found for table students.student_id in database.\n",
      "Warning: No close match found for table classes.class_id in database.\n",
      "Warning: No close match found for table classes.teacher_id in database.\n",
      "Warning: No close match found for table teachers.teacher_id in database.\n",
      "Warning: No close match found for table ref_address_types.address_type_description in database.\n",
      "Warning: No close match found for table ref_address_types.address_type_code in database.\n",
      "Warning: No close match found for table students.bio_data in database.\n",
      "Warning: No close match found for table teachers.teacher_details in database.\n",
      "Warning: No close match found for table students_addresses.address_type_code in database.\n",
      "Warning: No close match found for table teachers.teacher_id in database.\n",
      "Warning: No close match found for table ```SQL--Columns:students.student_id in database.\n",
      "Warning: No close match found for table students_addresses.address_type_code in database.\n",
      "Warning: No close match found for table students.student_id in database.\n",
      "Warning: No close match found for table classes.class_id in database.\n",
      "Warning: No close match found for table classes.teacher_id in database.\n",
      "Warning: No close match found for table ref_address_types.address_type_description in database.\n",
      "Warning: No close match found for table ref_event_types.event_type_description in database.\n",
      "Warning: No close match found for table ref_address_types.address_type_description in database.\n",
      "Warning: No close match found for table ref_address_types.address_type_code in database.\n",
      "Warning: No close match found for table ref_event_types.event_type_description in database.\n",
      "Warning: No close match found for table ref_event_types.event_type_code in database.\n",
      "Warning: No close match found for table students_addresses.address_type_code in database.\n",
      "Warning: No close match found for table student_events.event_type_code in database.\n",
      "Warning: No close match found for table students.bio_data in database.\n",
      "Warning: No close match found for table teachers.teacher_details in database.\n",
      "Warning: No close match found for table students.student_id in database.\n",
      "Warning: No close match found for table ```SQL--Columns:teachers.teacher_id in database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 676/2147 [00:06<00:11, 129.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No close match found for table Top in database.\n",
      "Warning: No close match found for table collections.collection_id in database.\n",
      "Warning: No close match found for table collection_subsets.collection_subset_id in database.\n",
      "Warning: No close match found for table collection_subsets.collection_subset_name in database.\n",
      "Warning: No close match found for table collection_subsets.collecrtion_subset_details in database.\n",
      "Warning: No close match found for table ```SQL--Columns:Topcollection in database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2147/2147 [00:16<00:00, 131.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.database_formatter import get_table_schema_with_samples, get_all_table_names\n",
    "from utils.sql_regularizator import format_and_lowercase_sql_query\n",
    "from utils.prompts import (\n",
    "    sql_generation_prompt_token_counter,\n",
    "    schema_linking_prompt_token_counter,\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "from sql_metadata import Parser\n",
    "import sqlite3\n",
    "BASE_DATABASES_DIR = \"./spider/test_database\"\n",
    "CONTEXT_WINDOW = 3000\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def get_closest_table_name(cursor, table_name):\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    available_tables = [row[0] for row in cursor.fetchall()]\n",
    "    closest_matches = get_close_matches(table_name, available_tables, n=1, cutoff=0.6)  \n",
    "    return closest_matches[0] if closest_matches else None\n",
    "\n",
    "def create_sql_generation_correct_tables(dataset, question, query, db_uri, correct_tables):\n",
    "    connection = sqlite3.connect(db_uri)\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    correct_columns = Parser(query).columns\n",
    "    database_schema_filtered = \"\"\n",
    "    all_tables = get_all_table_names(db_uri)\n",
    "    for table in reversed(correct_tables.split(\",\")):\n",
    "        closest_table_name = get_closest_table_name(cursor, table)\n",
    "        if closest_table_name:\n",
    "            database_schema_filtered += get_table_schema_with_samples(db_uri, closest_table_name)\n",
    "            database_schema_filtered += \"\\n\"\n",
    "        else:\n",
    "            print(f\"Warning: No close match found for table {table} in database.\")\n",
    "    database_schema = \"\"\n",
    "    for table in all_tables:\n",
    "        database_schema += get_table_schema_with_samples(db_uri, table)\n",
    "        database_schema += \"\\n\"\n",
    "    if (\n",
    "        schema_linking_prompt_token_counter(question, database_schema, correct_tables, correct_columns, tokenizer)\n",
    "        <= CONTEXT_WINDOW\n",
    "    ):\n",
    "        dataset.append(\n",
    "            {\n",
    "                \"db_id\": db_uri.split(\"/\")[-1].split(\".\")[0],\n",
    "                \"question\": question,\n",
    "                \"query\": query,\n",
    "                \"filtered_database_schema\": database_schema_filtered,\n",
    "                \"database_schema\": database_schema,\n",
    "                \"correct_tables\": \", \".join(correct_tables),\n",
    "                \"correct_columns\": \", \".join(correct_columns),\n",
    "            }\n",
    "        )\n",
    "    connection.close()\n",
    "    return dataset\n",
    "def load_spider_dev_set():\n",
    "    df = pd.read_csv(\"generated_test_schema_links_test2000.csv\")\n",
    "    df.iloc[:, :1] = df.iloc[:, :1].apply(lambda x: x.str.replace(' ', ''), axis=1)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load Spider dev set\n",
    "    df = load_spider_dev_set()\n",
    "    filtered_finetuning_dataset = []\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        db_id = row[\"db_id\"]\n",
    "        question = row[\"question\"]\n",
    "        query = row[\"query\"]\n",
    "        correct_tabs=row[\"predicted_tables\"]\n",
    "        #print(correct_tabs)\n",
    "        formatted_query = format_and_lowercase_sql_query(query)\n",
    "        db_uri = f\"{BASE_DATABASES_DIR}/{db_id}/{db_id}.sqlite\"\n",
    "        filtered_validation_dataset = create_sql_generation_correct_tables(\n",
    "            filtered_finetuning_dataset, question, formatted_query, db_uri, correct_tabs\n",
    "        )\n",
    "    filtered_validation_dataset = pd.DataFrame(filtered_validation_dataset)\n",
    "    filtered_validation_dataset.to_csv('useful_val_dataset4.csv')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.19 ('dtssql': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "6bdc3ee963768a78fc6892655c7d9a9a665a5ef67e391b4e3f554e2ac27cd423"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08d81d35451441abb5a8069816d96bf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16576d8e9bca4a978cf1807800d2993f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f87cf27bd7aa4c5fbcb796155236a983",
      "placeholder": "​",
      "style": "IPY_MODEL_a0010a2bcdc94d609fe271442e1db441",
      "value": " 2/2 [01:14&lt;00:00, 34.39s/it]"
     }
    },
    "30c71ab2e03d40d7968624b3dc15656c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a49f174c025644d7a99e414244390a0d",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f30459f7d7254a7abc3cabe448a60681",
      "value": 2
     }
    },
    "4fde92ad16cc4bd18d9c48dc91d28696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e2db7ee351248f4b08587a275bfde8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08d81d35451441abb5a8069816d96bf4",
      "placeholder": "​",
      "style": "IPY_MODEL_eed7debb70434c16aeda3d744d131d30",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "a0010a2bcdc94d609fe271442e1db441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a49f174c025644d7a99e414244390a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed7debb70434c16aeda3d744d131d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0d5986597124099bf09d298575c5126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e2db7ee351248f4b08587a275bfde8a",
       "IPY_MODEL_30c71ab2e03d40d7968624b3dc15656c",
       "IPY_MODEL_16576d8e9bca4a978cf1807800d2993f"
      ],
      "layout": "IPY_MODEL_4fde92ad16cc4bd18d9c48dc91d28696"
     }
    },
    "f30459f7d7254a7abc3cabe448a60681": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f87cf27bd7aa4c5fbcb796155236a983": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
